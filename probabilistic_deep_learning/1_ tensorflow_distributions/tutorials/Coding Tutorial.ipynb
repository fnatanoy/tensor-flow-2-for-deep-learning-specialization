{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.1.0\n",
      "TFP version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"TFP version:\", tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports and setting fixed random seed to have reproducibility\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Tutorials\n",
    "#### 1. [Univariate Distributions](#univariate_distributions)\n",
    "#### 2. [Multivariate Distributions](#multivariate_distributions)\n",
    "#### 3. [The Independent Distribution](#the_independent_distribution)\n",
    "#### 4. [Sampling and log probs](#sampling_and_log_probs)\n",
    "#### 5. [Trainable Distributions](#trainable_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Univariate distributions\n",
    "<a id='univariate_distributions'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a normal distribution from Tensorflow Distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the chosen distribution...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or sample multiple times\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain value of probability's density\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain value of logprobability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that this really is the log of the probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram, approximating the density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the exponential distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample as before\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Bernoulli distribution (discrete)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A word of caution on discrete distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Bernoulli prob and see that 0.5 and -1 do not give the correct probability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate the scores to see what is occurring under the hood\n",
    "\n",
    "def my_bernoulli(p_success, k):\n",
    "    return np.power(p_success,k)*np.power((1-p_success),(1-k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate it as before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with batch distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.Bernoulli 'Bernoulli' batch_shape=[5] event_shape=[] dtype=int32>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a batched Bernoulli distribution\n",
    "\n",
    "bernoulli_batch = tfd.Bernoulli(probs=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "bernoulli_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from it, noting the shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.Bernoulli 'Bernoulli' batch_shape=[1, 3, 2] event_shape=[] dtype=int32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a batch shape with higher rank\n",
    "\n",
    "probs = [[[0.5, 0.5], \n",
    "          [0.8, 0.3], \n",
    "          [0.25, 0.75]]]\n",
    "bernoulli_batch_2D = tfd.Bernoulli(probs=probs)\n",
    "bernoulli_batch_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from this batch of distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
       "array([[[0.5       , 0.5       ],\n",
       "        [0.19999999, 0.7       ],\n",
       "        [0.25      , 0.75      ]]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine probabilities from this batch distribution\n",
    "\n",
    "bernoulli_batch_2D.prob([[[1, 0], \n",
    "                         [0, 0], \n",
    "                         [1, 1]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id='multivariate_distributions'></a>\n",
    "## Multivariate Distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic multivariate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2D multivariate Gaussian with diagonal covariance matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normal_diag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-cb35c903b796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make a plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal_diag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'equal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normal_diag' is not defined"
     ]
    }
   ],
   "source": [
    "# Make a plot\n",
    "\n",
    "plt_sample = normal_diag.sample(10000)\n",
    "plt.scatter(plt_sample[:, 0], plt_sample[:, 1], marker='.', alpha=0.05)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batches of multivariate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three \"batches\" of multivariate normals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample for a plot -- notice the shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt_sample_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-cb26ffcaad71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt_sample_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#take the ith batch [samples x event_shape]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt_sample_batch' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAADGCAYAAADlokXFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADj1JREFUeJzt3V+IpXd9BvDn290G/FcjzSq6SWhaVuO2mKJjKtI/sdKaTS+2Qi4SbUODsiwYsTcloYW24E1FCiJGlyWE4I17Y7CxrE1Li6YQU7OBmGSVyBjbZIyQjYoFhaYbv704Z9uZ6Wzm7O75zewZPx8YmPd9f3t+DyfnC0/OOXNOdXcAABjj57Y7AADATqZsAQAMpGwBAAykbAEADKRsAQAMpGwBAAy0admqqrur6rmqeuIs16uqPllVy1X1WFW9df4xAQAW0yzPbN2T5PqXuH4gyb7pz6Ekn7nwWAAAO8OmZau7H0jyg5dYcjDJZ3vioSSXVtXr5xUQAGCRzeM9W3uTPLPqeGV6DgDgZ97uOdxGbXBuw+8AqqpDmbzUmFe84hVvu/rqq+ewPVy4Rx555Pnu3rPV+5oJLlZmAta6kJmYR9laSXLFquPLkzy70cLuPprkaJIsLS31iRMn5rA9XLiq+o/t2NdMcLEyE7DWhczEPF5GvC/JLdO/SnxHkh919/fmcLsAAAtv02e2qupzSa5LcllVrST5qyQ/nyTdfSTJ8SQ3JFlO8pMkt44KCwCwaDYtW9198ybXO8mH5pYIAGAH8QnyAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAA81Utqrq+qp6sqqWq+qODa6/uqq+WFVfr6qTVXXr/KMCACyeTctWVe1KcmeSA0n2J7m5qvavW/ahJN/o7muSXJfkb6vqkjlnBQBYOLM8s3VtkuXufqq7X0hyLMnBdWs6yauqqpK8MskPkpyea1IAgAU0S9nam+SZVccr03OrfSrJm5M8m+TxJB/p7p+uv6GqOlRVJ6rqxKlTp84zMuwcZgLWMhPsRLOUrdrgXK87fk+SR5O8IcmvJ/lUVf3C//tH3Ue7e6m7l/bs2XPOYWGnMROwlplgJ5qlbK0kuWLV8eWZPIO12q1J7u2J5STfSXL1fCICACyuWcrWw0n2VdVV0ze935TkvnVrnk7y7iSpqtcleVOSp+YZFABgEe3ebEF3n66q25Lcn2RXkru7+2RVHZ5eP5Lko0nuqarHM3nZ8fbufn5gbgCAhbBp2UqS7j6e5Pi6c0dW/f5skt+fbzQAgMXnE+QBAAZStgAABlK2AAAGUrYAAAZStgAABlK2AAAGUrYAAAZStgAABlK2AAAGUrYAAAZStgAABlK2AAAGUrYAAAZStgAABlK2AAAGUrYAAAZStgAABlK2AAAGUrYAAAZStgAABlK2AAAGUrYAAAZStgAABpqpbFXV9VX1ZFUtV9UdZ1lzXVU9WlUnq+or840JALCYdm+2oKp2Jbkzye8lWUnycFXd193fWLXm0iSfTnJ9dz9dVa8dFRgAYJHM8szWtUmWu/up7n4hybEkB9eteV+Se7v76STp7ufmGxMAYDHNUrb2Jnlm1fHK9Nxqb0zymqr6clU9UlW3zCsgAMAi2/RlxCS1wbne4HbeluTdSV6W5KtV9VB3f2vNDVUdSnIoSa688spzTws7jJmAtcwEO9Esz2ytJLli1fHlSZ7dYM0/dPePu/v5JA8kuWb9DXX30e5e6u6lPXv2nG9m2DHMBKxlJtiJZilbDyfZV1VXVdUlSW5Kct+6NX+X5LeqandVvTzJbyT55nyjAgAsnk1fRuzu01V1W5L7k+xKcnd3n6yqw9PrR7r7m1X1D0keS/LTJHd19xMjgwMALIJZ3rOV7j6e5Pi6c0fWHX88ycfnFw0AYPH5BHkAgIGULQCAgZQtAICBlC0AgIGULQCAgZQtAICBlC0AgIGULQCAgZQtAICBlC0AgIGULQCAgZQtAICBlC0AgIGULQCAgZQtAICBlC0AgIGULQCAgZQtAICBlC0AgIGULQCAgZQtAICBlC0AgIGULQCAgZQtAICBZipbVXV9VT1ZVctVdcdLrHt7Vb1YVTfOLyIAwOLatGxV1a4kdyY5kGR/kpurav9Z1n0syf3zDgkAsKhmeWbr2iTL3f1Ud7+Q5FiSgxus+3CSzyd5bo75AAAW2ixla2+SZ1Ydr0zP/a+q2pvkvUmOzC8aAMDim6Vs1Qbnet3xJ5Lc3t0vvuQNVR2qqhNVdeLUqVOzZoQdy0zAWmaCnWiWsrWS5IpVx5cneXbdmqUkx6rq35PcmOTTVfWH62+ou49291J3L+3Zs+c8I8POYSZgLTPBTrR7hjUPJ9lXVVcl+W6Sm5K8b/WC7r7qzO9VdU+Sv+/uL8wxJwDAQtq0bHX36aq6LZO/MtyV5O7uPllVh6fXvU8LAOAsZnlmK919PMnxdec2LFnd/ScXHgsAYGfwCfIAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADKVsAAAMpWwAAAylbAAADzVS2qur6qnqyqpar6o4Nrr+/qh6b/jxYVdfMPyoAwOLZtGxV1a4kdyY5kGR/kpurav+6Zd9J8jvd/ZYkH01ydN5BAQAW0SzPbF2bZLm7n+ruF5IcS3Jw9YLufrC7fzg9fCjJ5fONCQCwmGYpW3uTPLPqeGV67mw+kORLG12oqkNVdaKqTpw6dWr2lLBDmQlYy0ywE81StmqDc73hwqp3ZVK2bt/oencf7e6l7l7as2fP7ClhhzITsJaZYCfaPcOalSRXrDq+PMmz6xdV1VuS3JXkQHd/fz7xAAAW2yzPbD2cZF9VXVVVlyS5Kcl9qxdU1ZVJ7k3yx939rfnHBABYTJs+s9Xdp6vqtiT3J9mV5O7uPllVh6fXjyT5yyS/mOTTVZUkp7t7aVxsAIDFMMvLiOnu40mOrzt3ZNXvH0zywflGAwBYfD5BHgBgIGULAGAgZQsAYCBlCwBgIGULAGAgZQsAYCBlCwBgIGULAGAgZQsAYCBlCwBgIGULAGAgZQsAYCBlCwBgIGULAGAgZQsAYCBlCwBgIGULAGAgZQsAYCBlCwBgIGULAGAgZQsAYCBlCwBgIGULAGCgmcpWVV1fVU9W1XJV3bHB9aqqT06vP1ZVb51/VACAxbNp2aqqXUnuTHIgyf4kN1fV/nXLDiTZN/05lOQzc84JALCQZnlm69oky939VHe/kORYkoPr1hxM8tmeeCjJpVX1+jlnBQBYOLOUrb1Jnll1vDI9d65rAAB+5uyeYU1tcK7PY02q6lAmLzMmyX9V1RMz7D/SZUmel2HbM2z3/knypu3Y1EzIcJHun5iJMy6G/xYybP/+yQXMxCxlayXJFauOL0/y7HmsSXcfTXI0SarqRHcvnVPaOZPh4siw3fufybAd+5oJGS7G/c9k2I59zYQMF+P+ZzKc77+d5WXEh5Psq6qrquqSJDcluW/dmvuS3DL9q8R3JPlRd3/vfEMBAOwUmz6z1d2nq+q2JPcn2ZXk7u4+WVWHp9ePJDme5IYky0l+kuTWcZEBABbHLC8jpruPZ1KoVp87sur3TvKhc9z76DmuH0GGie3OsN37JzKcIcPEdmfY7v0TGc6QYWK7M2z3/skFZKhJTwIAYARf1wMAMNDwsnUxfNXPDBneP937sap6sKqu2cr9V617e1W9WFU3znP/WTNU1XVV9WhVnayqr2x1hqp6dVV9saq+Ps0w1/f+VdXdVfXc2f6UfKu+dspMmIlZM5iJrcthJszE9PbHzER3D/vJ5A31307yy0kuSfL1JPvXrbkhyZcy+ayudyT5t23I8M4kr5n+fmCeGWbZf9W6f8nkvXE3bsN9cGmSbyS5cnr82m3I8OdJPjb9fU+SHyS5ZI4ZfjvJW5M8cZbrQx+L53A/mIk2E9M1ZmILcpgJM7Hq9ofMxOhnti6Gr/rZNEN3P9jdP5wePpTJ54Rt2f5TH07y+STPzXHvc8nwviT3dvfTSdLd884xS4ZO8qqqqiSvzGSITs8rQHc/ML3Ns9mKr50yE2biXDKYia3JYSbMxOTGB83E6LJ1MXzVz7ne/gcyaa1btn9V7U3y3iRHMsYs98Ebk7ymqr5cVY9U1S3bkOFTSd6cyQfiPp7kI9390znneClb8bVTZsJMnEsGM7E1OcyEmZjVeT0WZ/rohwswt6/6GZxhsrDqXZkM0W9u8f6fSHJ7d784KetzN0uG3UneluTdSV6W5KtV9VB3f2sLM7wnyaNJfjfJryT5p6r61+7+zzll2Mzox+Kse5gJM3GGmdiaHGbCTMzqvB6Lo8vW3L7qZ3CGVNVbktyV5EB3f3+L919Kcmw6QJcluaGqTnf3F7Yww0qS57v7x0l+XFUPJLkmybyGaJYMtyb5m568ML5cVd9JcnWSr80pw2ZGPxZn3cNMmIkzzMTW5DATZmJW5/dYPNc3j53LTyZl7qkkV+X/3uz2q+vW/EHWvtnsa9uQ4cpMPv3+ndtxH6xbf0/m/8bHWe6DNyf55+nalyd5IsmvbXGGzyT56+nvr0vy3SSXzfm++KWc/Y2PQx+L53A/mIm1681EmwkzYSamaxZyJub6gDlLsBsyab3fTvIX03OHkxye/l5J7pxefzzJ0jZkuCvJDzN5avLRJCe2cv91a+c+RLNmSPJnmfylyRNJ/nQb/ju8Ick/Th8HTyT5oznv/7kk30vy35n838kHtvqxOOP9YCbWrjUTZsJMrF1rJhZsJnyCPADAQD5BHgBgIGULAGAgZQsAYCBlCwBgIGULAGAgZQsAYCBlCwBgIGULAGCg/wHgplov6p75agAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot samples from the batched multivariate Gaussian\n",
    "\n",
    "fig, axs = (plt.subplots(1, 3, sharex=True, sharey=True, figsize=(10, 3)))\n",
    "titles = ['cov_diag=[1, 2]','cov_diag=[2, 1]', 'cov_diag=[2, 2]']\n",
    "\n",
    "for i, (ax, title) in enumerate(zip(axs,titles)):\n",
    "    samples = plt_sample_batch[:,i,:] #take the ith batch [samples x event_shape]\n",
    "    ax.scatter(samples[:, 0], samples[:, 1], marker='.', alpha=0.05)\n",
    "    ax.set_title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***\n",
    "<a id='the_independent_distribution'></a>\n",
    "## The Independent Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by defining a batch of two univariate Gaussians, then\n",
    "# combine them into a bivariate Gaussian with independent components\n",
    "locs = [-1, 1]\n",
    "scales = [0.5, 1.0]\n",
    "batch_of_normals = tfd.Normal(loc=locs, scale=scales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Univariate density functions\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "t = np.linspace(-4, 4, 10000)\n",
    "densities = batch_of_normals.prob(np.repeat(t[:, np.newaxis], 2, axis=1)) # each column is a vector of densities for one distn\n",
    "\n",
    "sns.lineplot(t, densities[:, 0], label='loc={}, scale={}'.format(locs[0], scales[0]))\n",
    "sns.lineplot(t, densities[:, 1], label='loc={}, scale={}'.format(locs[1], scales[1]))\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.Normal 'Normal' batch_shape=[2] event_shape=[] dtype=float32>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check their batch_shape and event_shape\n",
    "batch_of_normals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Independent to convert the batch shape to the event shape\n",
    "bivariane_normal = t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that dimension from batch_shape has shifted to event_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bivariate_normal_from_Independent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-ebf1e73435fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a plot showing joint density contours and marginal density functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbivariate_normal_from_Independent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bivariate_normal_from_Independent' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a plot showing joint density contours and marginal density functions\n",
    "\n",
    "samples = bivariate_normal_from_Independent.sample(10000)\n",
    "x1 = samples[:, 0]\n",
    "x2 = samples[:, 1]\n",
    "sns.jointplot(x1, x2, kind=\"kde\", space=0, color='b', xlim=[-4, 4], ylim=[-4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MultivariateNormalDiag to create the equivalent distribution\n",
    "# Note that diagonal covariance matrix => no correlation => independence (for the multivariate normal distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bivariate_normal_from_Multivariate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-1cbbcdc840ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Summarise how Independent has been used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbivariate_normal_from_Multivariate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bivariate_normal_from_Multivariate' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the joint density function of bivariate_normal_from_Independent\n",
    "# Refer back to bivariate_normal_from_Independent to show that the plot is the same\n",
    "# Summarise how Independent has been used\n",
    "\n",
    "samples = bivariate_normal_from_Multivariate.sample(10000)\n",
    "x1 = samples[:, 0]\n",
    "x2 = samples[:, 1]\n",
    "sns.jointplot(x1, x2, kind=\"kde\", space=0, color='b', xlim=[-4, 4], ylim=[-4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting batch dimensions to event dimensions using \n",
    "`reinterpreted_batch_ndims`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate use of reinterpreted_batch_ndims\n",
    "# By default all batch dims except the first are transferred to event dims\n",
    "\n",
    "loc_grid = [[-100., -100.],\n",
    "            [100., 100.],\n",
    "            [0., 0.]]\n",
    "scale_grid = [[1., 10.],\n",
    "              [1., 10.],\n",
    "              [1., 1.]]\n",
    "\n",
    "normals_batch_3by2_event_1 = tfd.Normal(loc=loc_grid, scale=scale_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight batch_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have a batch of 3 bivariate normal distributions,\n",
    "# each parametrised by a column of our original parameter grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate log_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can reinterpret _all_ batch dimensions as event dimensions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take log_probs \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `Independent` to build a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to `newsgroups` data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, just load the dataset, fetch train/test splits, probably choose a subset of the data.\n",
    "\n",
    "Construct the class conditional feature distribution (with Independent, using the Naive Bayes assumption) and sample from it.\n",
    "\n",
    "We can just use the ML estimates for parameters, in later tutorials we will learn them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience function for retrieving the 20 newsgroups data set\n",
    "\n",
    "# Usenet was a forerunner to modern internet forums\n",
    "# Users could post and read articles\n",
    "# Newsgroup corresponded to a topic\n",
    "# Example topics in this data set: IBM computer hardware, baseball\n",
    "# Our objective is to use an article's contents to predict its newsgroup,\n",
    "# a 20-class classification problem.\n",
    "\n",
    "# 18000 newsgroups, posts on 20 topics\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train data\n",
    "newsgroups_data = fetch_20newsgroups(data_home=\"20_Newgroup_Data/\", subset=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _20newsgroups_dataset:\n",
      "\n",
      "The 20 newsgroups text dataset\n",
      "------------------------------\n",
      "\n",
      "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
      "20 topics split in two subsets: one for training (or development)\n",
      "and the other one for testing (or for performance evaluation). The split\n",
      "between the train and test set is based upon a messages posted before\n",
      "and after a specific date.\n",
      "\n",
      "This module contains two loaders. The first one,\n",
      ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
      "returns a list of the raw texts that can be fed to text feature\n",
      "extractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\n",
      "with custom parameters so as to extract feature vectors.\n",
      "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
      "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
      "extractor.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   ==========\n",
      "    Classes                     20\n",
      "    Samples total            18846\n",
      "    Dimensionality               1\n",
      "    Features                  text\n",
      "    =================   ==========\n",
      "\n",
      "Usage\n",
      "~~~~~\n",
      "\n",
      "The :func:`sklearn.datasets.fetch_20newsgroups` function is a data\n",
      "fetching / caching functions that downloads the data archive from\n",
      "the original `20 newsgroups website`_, extracts the archive contents\n",
      "in the ``~/scikit_learn_data/20news_home`` folder and calls the\n",
      ":func:`sklearn.datasets.load_files` on either the training or\n",
      "testing set folder, or both of them::\n",
      "\n",
      "  >>> from sklearn.datasets import fetch_20newsgroups\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train')\n",
      "\n",
      "  >>> from pprint import pprint\n",
      "  >>> pprint(list(newsgroups_train.target_names))\n",
      "  ['alt.atheism',\n",
      "   'comp.graphics',\n",
      "   'comp.os.ms-windows.misc',\n",
      "   'comp.sys.ibm.pc.hardware',\n",
      "   'comp.sys.mac.hardware',\n",
      "   'comp.windows.x',\n",
      "   'misc.forsale',\n",
      "   'rec.autos',\n",
      "   'rec.motorcycles',\n",
      "   'rec.sport.baseball',\n",
      "   'rec.sport.hockey',\n",
      "   'sci.crypt',\n",
      "   'sci.electronics',\n",
      "   'sci.med',\n",
      "   'sci.space',\n",
      "   'soc.religion.christian',\n",
      "   'talk.politics.guns',\n",
      "   'talk.politics.mideast',\n",
      "   'talk.politics.misc',\n",
      "   'talk.religion.misc']\n",
      "\n",
      "The real data lies in the ``filenames`` and ``target`` attributes. The target\n",
      "attribute is the integer index of the category::\n",
      "\n",
      "  >>> newsgroups_train.filenames.shape\n",
      "  (11314,)\n",
      "  >>> newsgroups_train.target.shape\n",
      "  (11314,)\n",
      "  >>> newsgroups_train.target[:10]\n",
      "  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\n",
      "\n",
      "It is possible to load only a sub-selection of the categories by passing the\n",
      "list of the categories to load to the\n",
      ":func:`sklearn.datasets.fetch_20newsgroups` function::\n",
      "\n",
      "  >>> cats = ['alt.atheism', 'sci.space']\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
      "\n",
      "  >>> list(newsgroups_train.target_names)\n",
      "  ['alt.atheism', 'sci.space']\n",
      "  >>> newsgroups_train.filenames.shape\n",
      "  (1073,)\n",
      "  >>> newsgroups_train.target.shape\n",
      "  (1073,)\n",
      "  >>> newsgroups_train.target[:10]\n",
      "  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
      "\n",
      "Converting text to vectors\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "In order to feed predictive or clustering models with the text data,\n",
      "one first need to turn the text into vectors of numerical values suitable\n",
      "for statistical analysis. This can be achieved with the utilities of the\n",
      "``sklearn.feature_extraction.text`` as demonstrated in the following\n",
      "example that extract `TF-IDF`_ vectors of unigram tokens\n",
      "from a subset of 20news::\n",
      "\n",
      "  >>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "  >>> categories = ['alt.atheism', 'talk.religion.misc',\n",
      "  ...               'comp.graphics', 'sci.space']\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
      "  ...                                       categories=categories)\n",
      "  >>> vectorizer = TfidfVectorizer()\n",
      "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
      "  >>> vectors.shape\n",
      "  (2034, 34118)\n",
      "\n",
      "The extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\n",
      "components by sample in a more than 30000-dimensional space\n",
      "(less than .5% non-zero features)::\n",
      "\n",
      "  >>> vectors.nnz / float(vectors.shape[0])       # doctest: +ELLIPSIS\n",
      "  159.01327...\n",
      "\n",
      ":func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which \n",
      "returns ready-to-use token counts features instead of file names.\n",
      "\n",
      ".. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\n",
      ".. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\n",
      "\n",
      "\n",
      "Filtering text for more realistic training\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "It is easy for a classifier to overfit on particular things that appear in the\n",
      "20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\n",
      "high F-scores, but their results would not generalize to other documents that\n",
      "aren't from this window of time.\n",
      "\n",
      "For example, let's look at the results of a multinomial Naive Bayes classifier,\n",
      "which is fast to train and achieves a decent F-score::\n",
      "\n",
      "  >>> from sklearn.naive_bayes import MultinomialNB\n",
      "  >>> from sklearn import metrics\n",
      "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
      "  ...                                      categories=categories)\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> clf = MultinomialNB(alpha=.01)\n",
      "  >>> clf.fit(vectors, newsgroups_train.target)\n",
      "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')  # doctest: +ELLIPSIS\n",
      "  0.88213...\n",
      "\n",
      "(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\n",
      "the training and test data, instead of segmenting by time, and in that case\n",
      "multinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\n",
      "yet of what's going on inside this classifier?)\n",
      "\n",
      "Let's take a look at what the most informative features are:\n",
      "\n",
      "  >>> import numpy as np\n",
      "  >>> def show_top10(classifier, vectorizer, categories):\n",
      "  ...     feature_names = np.asarray(vectorizer.get_feature_names())\n",
      "  ...     for i, category in enumerate(categories):\n",
      "  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\n",
      "  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
      "  ...\n",
      "  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
      "  alt.atheism: edu it and in you that is of to the\n",
      "  comp.graphics: edu in graphics it is for and of to the\n",
      "  sci.space: edu it that is in and space to of the\n",
      "  talk.religion.misc: not it you in is that and to of the\n",
      "\n",
      "\n",
      "You can now see many things that these features have overfit to:\n",
      "\n",
      "- Almost every group is distinguished by whether headers such as\n",
      "  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\n",
      "- Another significant feature involves whether the sender is affiliated with\n",
      "  a university, as indicated either by their headers or their signature.\n",
      "- The word \"article\" is a significant feature, based on how often people quote\n",
      "  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\n",
      "  wrote:\"\n",
      "- Other features match the names and e-mail addresses of particular people who\n",
      "  were posting at the time.\n",
      "\n",
      "With such an abundance of clues that distinguish newsgroups, the classifiers\n",
      "barely have to identify topics from text at all, and they all perform at the\n",
      "same high level.\n",
      "\n",
      "For this reason, the functions that load 20 Newsgroups data provide a\n",
      "parameter called **remove**, telling it what kinds of information to strip out\n",
      "of each file. **remove** should be a tuple containing any subset of\n",
      "``('headers', 'footers', 'quotes')``, telling it to remove headers, signature\n",
      "blocks, and quotation blocks respectively.\n",
      "\n",
      "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
      "  ...                                      remove=('headers', 'footers', 'quotes'),\n",
      "  ...                                      categories=categories)\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(pred, newsgroups_test.target, average='macro')  # doctest: +ELLIPSIS\n",
      "  0.77310...\n",
      "\n",
      "This classifier lost over a lot of its F-score, just because we removed\n",
      "metadata that has little to do with topic classification.\n",
      "It loses even more if we also strip this metadata from the training data:\n",
      "\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
      "  ...                                       remove=('headers', 'footers', 'quotes'),\n",
      "  ...                                       categories=categories)\n",
      "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
      "  >>> clf = MultinomialNB(alpha=.01)\n",
      "  >>> clf.fit(vectors, newsgroups_train.target)\n",
      "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')  # doctest: +ELLIPSIS\n",
      "  0.76995...\n",
      "\n",
      "Some other classifiers cope better with this harder version of the task. Try\n",
      "running :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\n",
      "the ``--filter`` option to compare the results.\n",
      "\n",
      ".. topic:: Recommendation\n",
      "\n",
      "  When evaluating text classifiers on the 20 Newsgroups data, you\n",
      "  should strip newsgroup-related metadata. In scikit-learn, you can do this by\n",
      "  setting ``remove=('headers', 'footers', 'quotes')``. The F-score will be\n",
      "  lower because it is more realistic.\n",
      "\n",
      ".. topic:: Examples\n",
      "\n",
      "   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\n",
      "\n",
      "   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More information about the data set\n",
    "print(newsgroups_data[\"DESCR\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example article\n",
    "newsgroups_data[\"data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Associated label\n",
    "newsgroups_data[\"target\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.autos'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name of label\n",
    "newsgroups_data[\"target_names\"][7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing boilerplate\n",
    "\n",
    "n_documents = len(newsgroups_data['data'])\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "    input='content',\n",
    "    binary=True,\n",
    "    max_df=0.25,\n",
    "    min_df=1.01/n_documents\n",
    ") # ignore common words, words that appear once\n",
    "binary_bag_of_words = count_vectorizer.fit_transform(newsgroups_data['data']) # input is a list of strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 56365)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape\n",
    "binary_bag_of_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 56365)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_bag_of_words[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['lerxst', 'wam', 'umd', 'where', 'thing', 'car', 'rac3',\n",
       "        'maryland', 'college', 'park', '15', 'wondering', 'anyone',\n",
       "        'could', 'enlighten', 'saw', 'day', 'door', 'sports', 'looked',\n",
       "        'late', '60s', 'early', '70s', 'called', 'bricklin', 'doors',\n",
       "        'were', 'really', 'small', 'addition', 'front', 'bumper',\n",
       "        'separate', 'rest', 'body', 'tellme', 'model', 'name', 'engine',\n",
       "        'specs', 'years', 'production', 'made', 'history', 'whatever',\n",
       "        'info', 'funky', 'looking', 'please', 'mail', 'thanks', 'il',\n",
       "        'brought', 'neighborhood'], dtype='<U80')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the fit has been successful\n",
    "\n",
    "count_vectorizer.inverse_transform(binary_bag_of_words[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict that will be useful later \n",
    "inv_vocabulary = {value:key for key, value in count_vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Naive Bayes classifier for `newsgroup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each feature vector $x$ is a list of indicators for whether a word appears in the article. $x_i$ is 1 if the $i$th word appears, and 0 otherwise. `inv_vocabulary` matches word indices $i$ to words.\n",
    "\n",
    "Each label $y$ is a value in $0, 1, \\ldots, 19$.\n",
    "\n",
    "The parts of a naive Bayes classifier for this problem can be summarised as:  \n",
    "\n",
    "\n",
    "- A probability distribution for the feature vector by class, $p(x|y = j)$ for each $j = 0, 1, \\ldots, 19$. These probability distributions are assumed to have independent components: we can factorize the joint probability as a product of marginal probabilities\n",
    "\\begin{equation}\n",
    "    p(x|y = j) = \\prod_{i=1}^d p(x_i|y = j)\n",
    "\\end{equation}\n",
    "These marginal probability distributions are Bernoulli distributions, each of which has a single parameter $\\theta_{ji} := p(x_i = 1|y = j)$. This parameter is the probability of observing word $i$ in an article of class $j$. \n",
    "\n",
    "- We will use the Laplace smoothed maximum likelihood estimate to compute these parameters. Laplace smoothing involves adding small counts to every feature for each class. Else, if a feature did not appear in the training set of a class, but then we observed it in our test data the log probability would be undefined.\n",
    "\n",
    "- A collection of class prior probabilities $p(y = j)$. These will be set by computing the class base rates in the training set.  \n",
    "\n",
    "\n",
    "- A function for computing the probability of class membership via Bayes' theorem:  \n",
    "\n",
    "\\begin{equation}\n",
    "    p(y = j|x) = \\frac{p(x|y = j)p(y = j)}{p(x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the parameter estimates (adjusted fraction of documents in class that contain word)\n",
    "\n",
    "n_classes = newsgroups_data['target'].max() + 1\n",
    "y = newsgroups_data['target']\n",
    "n_words = binary_bag_of_words.shape[1]\n",
    "\n",
    "alpha = 1e-6 # parameters for Laplace smoothing\n",
    "\n",
    "theta = np.zeros([n_classes, n_words]) # stores parameter values - prob. word given class\n",
    "for c_k in range(n_classes): # 0, 1, ..., 19\n",
    "    class_mask = (y == c_k)\n",
    "    N = class_mask.sum() # number of articles in class\n",
    "    theta[c_k, :] = (binary_bag_of_words[class_mask, :].sum(axis=0) + alpha)/(N + alpha*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 56365)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable word in class alt.atheism is \"people\".\n",
      "Most probable word in class comp.graphics is \"graphics\".\n",
      "Most probable word in class comp.os.ms-windows.misc is \"windows\".\n",
      "Most probable word in class comp.sys.ibm.pc.hardware is \"thanks\".\n",
      "Most probable word in class comp.sys.mac.hardware is \"mac\".\n",
      "Most probable word in class comp.windows.x is \"window\".\n",
      "Most probable word in class misc.forsale is \"sale\".\n",
      "Most probable word in class rec.autos is \"car\".\n",
      "Most probable word in class rec.motorcycles is \"dod\".\n",
      "Most probable word in class rec.sport.baseball is \"he\".\n",
      "Most probable word in class rec.sport.hockey is \"ca\".\n",
      "Most probable word in class sci.crypt is \"clipper\".\n",
      "Most probable word in class sci.electronics is \"use\".\n",
      "Most probable word in class sci.med is \"reply\".\n",
      "Most probable word in class sci.space is \"space\".\n",
      "Most probable word in class soc.religion.christian is \"god\".\n",
      "Most probable word in class talk.politics.guns is \"people\".\n",
      "Most probable word in class talk.politics.mideast is \"people\".\n",
      "Most probable word in class talk.politics.misc is \"people\".\n",
      "Most probable word in class talk.religion.misc is \"he\".\n"
     ]
    }
   ],
   "source": [
    "# Check whether the most probable word in each class is reasonable\n",
    "\n",
    "most_probable_word_ix = theta.argmax(axis=1) # most probable word for each class\n",
    "\n",
    "for j, ix in enumerate(most_probable_word_ix):\n",
    "    print('Most probable word in class {} is \"{}\".'.format(newsgroups_data['target_names'][j],\n",
    "                                                           inv_vocabulary[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.Independent 'IndependentBernoulli' batch_shape=[20] event_shape=[56365] dtype=int32>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a distribution for each class\n",
    "batch_of_bernoullis = tfd.Bernoulli(probs=theta)\n",
    "p_x_given_y = tfd.Independent(batch_of_bernoullis, reinterpreted_batch_ndims=1)\n",
    "\n",
    "p_x_given_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 20, 56365])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a sample of words from each class\n",
    "\n",
    "n_samples = 10\n",
    "sample = p_x_given_y.sample(n_samples)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a class\n",
    "\n",
    "chosen_class = 15\n",
    "newsgroups_data['target_names'][chosen_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 56365), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indicators for words that appear in the sample\n",
    "\n",
    "class_sample = sample[:, chosen_class, :]\n",
    "class_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '15426', '18833', '22', '334', '5of5', 'actually', 'ad',\n",
       "       'am', 'anyhting', 'apostacy', 'appreciated', 'apr', 'aras',\n",
       "       'arrogance', 'assert', 'australia', 'been', 'body', 'bother',\n",
       "       'carson', 'catholic', 'ceremony', 'children', 'christian',\n",
       "       'christianity', 'christopher', 'church', 'claim', 'clearest',\n",
       "       'clearly', 'come', 'common', 'confusing', 'contradictory',\n",
       "       'contribution', 'copyright', 'decree', 'difficulty', 'dismiss',\n",
       "       'earlier', 'either', 'essence', 'even', 'example', 'fails',\n",
       "       'faith', 'finabo', 'further', 'god', 'gov', 'grounded', 'happened',\n",
       "       'hell', 'him', 'his', 'history', 'home', 'hope', 'however',\n",
       "       'human', 'ibm', 'incorporate', 'inspired', 'intellectual',\n",
       "       'interim', 'john', 'johnsd2', 'least', 'leslie', 'life',\n",
       "       'literally', 'look', 'looked', 'love', 'luckily', 'magazine',\n",
       "       'man', 'martyred', 'mentioning', 'midst', 'mind', 'mindlink',\n",
       "       'mmalt', 'much', 'murder', 'never', 'noted', 'nothing', 'now',\n",
       "       'off', 'old', 'once', 'others', 'our', 'own', 'parties', 'person',\n",
       "       'personal', 'physics', 'prince', 'problem', 'punishing', 'quite',\n",
       "       'really', 'recognize', 'regarded', 'religion', 'results', 'return',\n",
       "       'says', 'science', 'self', 'send', 'sherman', 'shrine', 'similar',\n",
       "       'spanked', 'st', 'steps', 'struggle', 'such', 'suppose', 'talks',\n",
       "       'taught', 'tell', 'tells', 'thoughtful', 'time', 'trust', 'try',\n",
       "       'understanding', 've', 'waiting', 'want', 'wasn', 'wrong'],\n",
       "      dtype='<U80')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform inverse transform to test quality of fit\n",
    "\n",
    "aa = count_vectorizer.inverse_transform(class_sample)\n",
    "aa[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id='sampling_and_log_probs'></a>\n",
    "## Sampling and log probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.MultivariateNormalDiag 'MultivariateNormalDiag' batch_shape=[3] event_shape=[2] dtype=float32>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Multivariate Distribution\n",
    "\n",
    "normal_distributions = tfd.MultivariateNormalDiag(loc=[[0.5, 1], [0.1, 0], [0, 0.2]],\n",
    "                                 scale_diag=[[2, 3], [1, 3], [4, 4]])\n",
    "normal_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3, 2), dtype=float32, numpy=\n",
       "array([[[ 1.1775086 ,  2.0349584 ],\n",
       "        [-0.56057847, -0.8564982 ],\n",
       "        [ 1.7540954 ,  3.5154264 ]],\n",
       "\n",
       "       [[-0.5718311 , -0.6060449 ],\n",
       "        [-0.9324248 , -8.8281145 ],\n",
       "        [ 0.9197962 , -1.984817  ]],\n",
       "\n",
       "       [[-0.09479177,  1.0497051 ],\n",
       "        [ 0.25928634, -1.3189373 ],\n",
       "        [ 4.9773383 , -3.1545756 ]],\n",
       "\n",
       "       [[-0.34269917,  1.2190639 ],\n",
       "        [ 0.08767394, -1.3796246 ],\n",
       "        [-2.8122177 , -3.9976852 ]],\n",
       "\n",
       "       [[-0.31372982,  3.1113029 ],\n",
       "        [ 0.25045082, -0.3559933 ],\n",
       "        [-3.8862326 , -7.258297  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "normal_distributions.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.MultivariateNormalDiag 'MultivariateNormalDiag' batch_shape=[2, 2] event_shape=[3] dtype=float32>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multivariate Normal batched Distribution\n",
    "# We are broadcasting batch shapes of `loc` and `scal_diag` \n",
    "# against each other\n",
    "\n",
    "loc = [[[0.3, 1.5, 1.], [0.2, 0.4, 2.8]],\n",
    "        [[2., 2.3, 8], [1.4, 1, 1.3]]]\n",
    "scale_diag = [0.4, 1., 0.7]\n",
    "normal_distributions = tfd.MultivariateNormalDiag(loc=loc, scale_diag=scale_diag)\n",
    "normal_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.Independent 'IndependentMultivariateNormalDiag' batch_shape=[2] event_shape=[2, 3] dtype=float32>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use independent to move part of the batch shape\n",
    "ind_normal_dist = tfd.Independent(normal_distributions, reinterpreted_batch_ndims=1)\n",
    "ind_normal_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw some samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `[B, E]` shaped input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `[E]` shaped input (broadcasting over batch size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#`[S, B, E]` shaped input (broadcasting over samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `[S, b, e]` shaped input, where [b, e] is broadcastable over [B, E]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes example\n",
    "\n",
    "Lets now use what we have learned and continue the Naive Bayes classifier we were building last tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a function get_data which:\n",
    "#   1) Fetches the 20 newsgroup dataset\n",
    "#   2) Performs a word count on the articles and binarizes the result\n",
    "#   3) Returns the data as a numpy matrix with the labels\n",
    "\n",
    "def get_data(categories):\n",
    "    \n",
    "    newsgroups_train_data = fetch_20newsgroups(data_home='20_Newsgroup_Data/',\n",
    "                                               subset='train', categories=categories)\n",
    "    newsgroups_test_data = fetch_20newsgroups(data_home='20_Newsgroup_Data/',\n",
    "                                              subset='test', categories=categories)\n",
    "\n",
    "    n_documents = len(newsgroups_train_data['data'])\n",
    "    count_vectorizer = CountVectorizer(input='content', binary=True,max_df=0.25, min_df=1.01/n_documents)\n",
    "    \n",
    "    train_binary_bag_of_words = count_vectorizer.fit_transform(newsgroups_train_data['data'])\n",
    "    test_binary_bag_of_words = count_vectorizer.transform(newsgroups_test_data['data']) \n",
    "\n",
    "    return (train_binary_bag_of_words.todense(), newsgroups_train_data['target']),  (test_binary_bag_of_words.todense(), newsgroups_test_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to conduct Laplace smoothing. This adds a base level of probability for a given feature\n",
    "# to occur in every class.\n",
    "\n",
    "def laplace_smoothing(labels, binary_data, n_classes):\n",
    "    # Compute the parameter estimates (adjusted fraction of documents in class that contain word)\n",
    "    n_words = binary_data.shape[1]\n",
    "    alpha = 1 # parameters for Laplace smoothing\n",
    "    theta = np.zeros([n_classes, n_words]) # stores parameter values - prob. word given class\n",
    "    for c_k in range(n_classes): # 0, 1, ..., 19\n",
    "        class_mask = (labels == c_k)\n",
    "        N = class_mask.sum() # number of articles in class\n",
    "        theta[c_k, :] = (binary_data[class_mask, :].sum(axis=0) + alpha)/(N + alpha*2)\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a subset of the 20 newsgroup dataset\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = get_data(categories=categories)\n",
    "smoothed_counts = laplace_smoothing(labels=train_labels, binary_data=train_data, n_classes=len(categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To now make our NB classifier we need to build three functions:\n",
    "* Compute the class priors\n",
    "* Build our class conditional distributions\n",
    "* Put it all together and classify our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which computes the prior probability of every class based on frequency of occurence in \n",
    "# the dataset\n",
    "\n",
    "def class_priors(n_classes, labels):\n",
    "    counts = np.zeros(n_classes)\n",
    "    for c_k in range(n_classes):\n",
    "        counts[c_k] = np.sum(np.where(labels==c_k, 1, 0))\n",
    "    priors = counts / np.sum(counts)\n",
    "    print('The class priors are {}'.format(priors))\n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class priors are [0.2359882  0.28711898 0.29154376 0.18534907]\n"
     ]
    }
   ],
   "source": [
    "# Run the function \n",
    "priors = class_priors(n_classes=len(categories), labels=train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will do a function that given the feature occurence counts returns a Bernoulli distribution of \n",
    "# batch_shape=number of classes and event_shape=number of features.\n",
    "def make_distributions(probs):\n",
    "    batch_of_bernoullis = tfd.Bernoulli(probs=probs)\n",
    "    dist = tfd.Independent(batch_of_bernoullis)\n",
    "    \n",
    "    return dist\n",
    "\n",
    "tf_dist = make_distributions(smoothed_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final function predict_sample which given the distribution, a test sample, and the class priors:\n",
    "#   1) Computes the class conditional probabilities given the sample\n",
    "#   2) Forms the joint likelihood\n",
    "#   3) Normalises the joint likelihood and returns the log prob\n",
    "\n",
    "def predict_sample(dist, sample, prior):\n",
    "    cond_probs = dist.log_prob(sample)\n",
    "    joint_liklihood = tf.add(np.log(priors), cond_probs)\n",
    "    normal_factor = tf.math.reduce_logsumexp(joint_liklihood, axis=-1, keepdims=True)\n",
    "    log_prob = joint_liklihood - normal_factor\n",
    "    \n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
       "array([-6.1736160e+01, -1.5258789e-05, -1.1619934e+01, -6.3327240e+01],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting one example from our test data\n",
    "log_prob = predict_sample(tf_dist, test_data[0], priors)\n",
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1  0.7848499112849504\n"
     ]
    }
   ],
   "source": [
    "# Loop over our test data and classify.\n",
    "\n",
    "probabilities = []\n",
    "for sample, label in zip(test_data, test_labels):\n",
    "    probabilities.append(tf.exp(predict_sample(tf_dist, sample, priors)))\n",
    "\n",
    "probabilities = np.asarray(probabilities)\n",
    "predicted_classes = np.argmax(probabilities, axis =-1)\n",
    "print('f1 ', f1_score(test_labels, predicted_classes, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 from sklean  0.8623389692276502\n"
     ]
    }
   ],
   "source": [
    "# Make a Bernoulli Naive Bayes classifier using sklearn with the same level of alpha smoothing. \n",
    "\n",
    "clf = BernoulliNB(alpha=0.01)\n",
    "clf.fit(train_data, train_labels)\n",
    "pred = clf.predict(test_data)\n",
    "print('f1 from sklean ', f1_score(test_labels, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id='trainable_distributions'></a>\n",
    "## Trainable Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an exponential distribution\n",
    "\n",
    "exponential = tfd.Exponential(rate=0.3,name='exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "\n",
    "plt.hist(exponential.sample(5000), bins=100, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'rate:0' shape=() dtype=float32, numpy=1.0>,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an exponential distribution with a trainable rate parameter\n",
    "\n",
    "exp_train = tfd.Exponential(rate=tf.Variable(1.0, name='rate'), name='exp_train')\n",
    "exp_train.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the negative log likelihood\n",
    "def nll(x_train, dist):\n",
    "    return -tf.reduce_mean(dist.log_prob(x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the loss and gradients\n",
    "@tf.function\n",
    "def get_loss_and_grads(x_train, distribution):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(distribution.trainable_variables)\n",
    "        loss = nll(x_train, distribution)\n",
    "        grads = tape.gradient(loss, distribution.trainable_variables)\n",
    "        \n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize\n",
    "\n",
    "def exponential_dist_optimisation(data, distribution):\n",
    "\n",
    "    # Keep results for plotting\n",
    "    train_loss_results = []\n",
    "    train_rate_results = []\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
    "\n",
    "    num_steps = 20\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        loss, grads = get_loss_and_grads(data, distribution)\n",
    "        optimizer.apply_gradients(zip(grads, distribution.trainable_variables))\n",
    "                                        \n",
    "        rate_value = distribution.rate.value()\n",
    "        train_loss_results.append(loss)\n",
    "        train_rate_results.append(rate_value)\n",
    "        print(\"Step {:03d}: Loss: {:.3f}: Rate: {:.3f}\".format(i, loss, rate_value))\n",
    "        \n",
    "    return train_loss_results, train_rate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 000: Loss: 3.315: Rate: 0.884\n",
      "Step 001: Loss: 3.054: Rate: 0.775\n",
      "Step 002: Loss: 2.824: Rate: 0.674\n",
      "Step 003: Loss: 2.628: Rate: 0.582\n",
      "Step 004: Loss: 2.471: Rate: 0.502\n",
      "Step 005: Loss: 2.354: Rate: 0.436\n",
      "Step 006: Loss: 2.276: Rate: 0.385\n",
      "Step 007: Loss: 2.231: Rate: 0.349\n",
      "Step 008: Loss: 2.210: Rate: 0.327\n",
      "Step 009: Loss: 2.202: Rate: 0.314\n",
      "Step 010: Loss: 2.199: Rate: 0.307\n",
      "Step 011: Loss: 2.199: Rate: 0.304\n",
      "Step 012: Loss: 2.198: Rate: 0.303\n",
      "Step 013: Loss: 2.198: Rate: 0.302\n",
      "Step 014: Loss: 2.198: Rate: 0.302\n",
      "Step 015: Loss: 2.198: Rate: 0.302\n",
      "Step 016: Loss: 2.198: Rate: 0.302\n",
      "Step 017: Loss: 2.198: Rate: 0.302\n",
      "Step 018: Loss: 2.198: Rate: 0.302\n",
      "Step 019: Loss: 2.198: Rate: 0.302\n"
     ]
    }
   ],
   "source": [
    "# Get some data and train\n",
    "sampled_data = exponential.sample(5000)\n",
    "train_loss_results, train_rate_results = exponential_dist_optimisation(\n",
    "    data=sampled_data,\n",
    "    distribution=exp_train,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact rate:  0.3\n",
      "Pred rate:   0.3016669\n"
     ]
    }
   ],
   "source": [
    "# Predicted value for the rate parameter\n",
    "\n",
    "pred_value = exp_train.rate.numpy()\n",
    "exact_value = exponential.rate.numpy()\n",
    "\n",
    "print(\"Exact rate: \", exact_value)\n",
    "print(\"Pred rate:  \", pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot to see the convergence of the estimated and true parameters\n",
    "\n",
    "tensor_exact_value = tf.constant(exact_value, shape=[len(train_rate_results)])\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Convergence')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Rate\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_rate_results, label='trainable rate variable')\n",
    "axes[1].plot(tensor_exact_value, label='exact rate')\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a function get_data which:\n",
    "#   1) Fetches the 20 newsgroup dataset\n",
    "#   2) Performs a word count on the articles and binarizes the result\n",
    "#   3) Returns the data as a numpy matrix with the labels\n",
    "\n",
    "def get_data(categories):\n",
    "\n",
    "    newsgroups_train_data = fetch_20newsgroups(data_home='20_Newsgroup_Data/',\n",
    "                                               subset='train', categories=categories)\n",
    "    newsgroups_test_data = fetch_20newsgroups(data_home='20_Newsgroup_Data/',\n",
    "                                              subset='test', categories=categories)\n",
    "\n",
    "    n_documents = len(newsgroups_train_data['data'])\n",
    "    count_vectorizer = CountVectorizer(input='content', binary=True,max_df=0.25, min_df=1.01/n_documents) \n",
    "    train_binary_bag_of_words = count_vectorizer.fit_transform(newsgroups_train_data['data']) \n",
    "    test_binary_bag_of_words = count_vectorizer.transform(newsgroups_test_data['data']) \n",
    "\n",
    "    return (train_binary_bag_of_words.todense(), newsgroups_train_data['target']),  (test_binary_bag_of_words.todense(), newsgroups_test_data['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to conduct laplace smoothing. This adds a base level of probability for a given feature\n",
    "# to occur in every class.\n",
    "\n",
    "def laplace_smoothing(labels, binary_data, n_classes):\n",
    "    # Compute the parameter estimates (adjusted fraction of documents in class that contain word)\n",
    "    n_words = binary_data.shape[1]\n",
    "    alpha = 1 # parameters for Laplace smoothing\n",
    "    theta = np.zeros([n_classes, n_words]) # stores parameter values - prob. word given class\n",
    "    for c_k in range(n_classes): # 0, 1, ..., 19\n",
    "        class_mask = (labels == c_k)\n",
    "        N = class_mask.sum() # number of articles in class\n",
    "        theta[c_k, :] = (binary_data[class_mask, :].sum(axis=0) + alpha)/(N + alpha*2)\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will do a function that given the feature occurence counts returns a Bernoulli distribution of \n",
    "# batch_shape=number of classes and event_shape=number of features.\n",
    "\n",
    "def make_distributions(probs):\n",
    "    batch_of_bernoullis = tfd.Bernoulli(probs=probs) # shape (n_classes, n_words)\n",
    "    dist = tfd.Independent(batch_of_bernoullis, reinterpreted_batch_ndims=1)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which computes the prior probability of every class based on frequency of occurence in \n",
    "# the dataset\n",
    "\n",
    "def class_priors(n_classes, labels):\n",
    "    counts = np.zeros(n_classes)\n",
    "    for c_k in range(n_classes):\n",
    "        counts[c_k] = np.sum(np.where(labels==c_k, 1, 0))\n",
    "    priors = counts / np.sum(counts)\n",
    "    print('The class priors are {}'.format(priors))\n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final function predict_sample which given the distribution, a test sample, and the class priors:\n",
    "#   1) Computes the class conditional probabilities given the sample\n",
    "#   2) Forms the joint likelihood\n",
    "#   3) Normalises the joint likelihood and returns the log prob\n",
    "\n",
    "def predict_sample(dist, sample, priors):\n",
    "    cond_probs = dist.log_prob(sample)\n",
    "    joint_likelihood = tf.add(np.log(priors), cond_probs)\n",
    "    norm_factor = tf.math.reduce_logsumexp(joint_likelihood, axis=-1, keepdims=True)\n",
    "    log_prob = joint_likelihood - norm_factor\n",
    "\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we learn the distribution using gradient tape\n",
    "\n",
    "def make_distribution_withGT(data, labels, nb_classes):\n",
    "\n",
    "    class_data = []\n",
    "    train_vars = []\n",
    "    distributions = []\n",
    "    for c in range(nb_classes):\n",
    "        train_vars.append(tf.Variable(initial_value=np.random.uniform(low=0.01, high =0.1, size=data.shape[-1])))\n",
    "        distributions.append(tfd.Bernoulli(probs=train_vars[c]))\n",
    "        class_mask = (labels == c)\n",
    "        class_data.append(data[class_mask, :])\n",
    "\n",
    "    for c_num in range(0,nb_classes):\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        print('\\n%-------------------%')\n",
    "        print('Class ', c_num)\n",
    "        print('%-------------------%')\n",
    "\n",
    "        for i in range(0,100):\n",
    "            loss, grads = get_loss_and_grads(class_data[c_num], distributions[c_num])\n",
    "            if (i%10==0):\n",
    "                print(f\"iter: {i}, loss: {loss}\")\n",
    "\n",
    "            optimizer.apply_gradients(zip(grads, distributions[c_num].trainable_variables))\n",
    "            eta = 1e-3\n",
    "            clipped_probs = tf.clip_by_value(\n",
    "                distributions[c_num].trainable_variables,\n",
    "                clip_value_min=eta,\n",
    "                clip_value_max=1.0,\n",
    "            )\n",
    "            train_vars[c_num] = tf.squeeze(clipped_probs)\n",
    "            \n",
    "\n",
    "    dist = tfd.Bernoulli(probs=train_vars)\n",
    "    dist = tfd.Independent(dist,reinterpreted_batch_ndims=1)\n",
    "\n",
    "    print(dist)\n",
    "\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class priors are [0.2359882  0.28711898 0.29154376 0.18534907]\n"
     ]
    }
   ],
   "source": [
    "# Make the same Naive Bayes classifier we did last tutorial\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = get_data(categories)\n",
    "\n",
    "smoothed_counts = laplace_smoothing(labels=train_labels, binary_data=train_data, n_classes=len(categories))\n",
    "\n",
    "priors = class_priors(n_classes=len(categories), labels=train_labels)\n",
    "tf_dist = make_distributions(smoothed_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%-------------------%\n",
      "Class  0\n",
      "%-------------------%\n",
      "iter: 0, loss: 0.07833053049234077\n",
      "iter: 10, loss: 0.06898671639281234\n",
      "iter: 20, loss: 0.0602724879002189\n",
      "iter: 30, loss: 0.05220998575788707\n",
      "iter: 40, loss: 0.044753796689009695\n",
      "iter: 50, loss: 0.037852977935136096\n",
      "iter: 60, loss: 0.03146886721638953\n",
      "iter: 70, loss: 0.02556174202679673\n",
      "iter: 80, loss: 0.020085770119792654\n",
      "iter: 90, loss: 0.015000301069308086\n",
      "\n",
      "%-------------------%\n",
      "Class  1\n",
      "%-------------------%\n",
      "iter: 0, loss: 0.07173497116515855\n",
      "iter: 10, loss: 0.06238654407981134\n",
      "iter: 20, loss: 0.053587008843512925\n",
      "iter: 30, loss: 0.045414516400187586\n",
      "iter: 40, loss: 0.03782651023454627\n",
      "iter: 50, loss: 0.03080046507793437\n",
      "iter: 60, loss: 0.02430829314586982\n",
      "iter: 70, loss: 0.018311586893132566\n",
      "iter: 80, loss: 0.012775010424234574\n",
      "iter: 90, loss: 0.0076577271629560215\n",
      "\n",
      "%-------------------%\n",
      "Class  2\n",
      "%-------------------%\n",
      "iter: 0, loss: 0.07829192473159087\n",
      "iter: 10, loss: 0.06920068724848787\n",
      "iter: 20, loss: 0.06082307961917272\n",
      "iter: 30, loss: 0.05318566704550133\n",
      "iter: 40, loss: 0.04625359205368629\n",
      "iter: 50, loss: 0.039985057104459404\n",
      "iter: 60, loss: 0.0343314112170119\n",
      "iter: 70, loss: 0.029238978386631975\n",
      "iter: 80, loss: 0.024657541250417737\n",
      "iter: 90, loss: 0.020531970127136874\n",
      "\n",
      "%-------------------%\n",
      "Class  3\n",
      "%-------------------%\n",
      "iter: 0, loss: 0.07949133021621442\n",
      "iter: 10, loss: 0.07024304689864577\n",
      "iter: 20, loss: 0.061632069176297696\n",
      "iter: 30, loss: 0.053654810523350305\n",
      "iter: 40, loss: 0.04626456892017967\n",
      "iter: 50, loss: 0.03940973517875044\n",
      "iter: 60, loss: 0.03305370755033618\n",
      "iter: 70, loss: 0.027160211122841484\n",
      "iter: 80, loss: 0.021684353997847346\n",
      "iter: 90, loss: 0.01656871517361482\n",
      "tfp.distributions.Independent(\"IndependentBernoulli\", batch_shape=[4], event_shape=[17495], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Now train the distributions with gradient tape\n",
    "\n",
    "GT_dist = make_distribution_withGT(data=train_data, labels=train_labels, nb_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1  0.8277872752536024\n",
      "f1  0.7848499112849504\n"
     ]
    }
   ],
   "source": [
    "# Compare the two results\n",
    "\n",
    "for dist in [GT_dist,tf_dist]:\n",
    "    probabilities = []\n",
    "    for sample, label in zip(test_data, test_labels):\n",
    "        probabilities.append(predict_sample(dist, sample, priors))\n",
    "\n",
    "    probabilities = np.asarray(probabilities)\n",
    "    predicted_classes = np.argmax(probabilities, axis =-1)\n",
    "    print('f1 ', f1_score(test_labels, predicted_classes, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
