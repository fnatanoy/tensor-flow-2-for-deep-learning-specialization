# Variational Autoencoders

Variational autoencoders are one of the most popular types of likelihood-based generative deep learning models. In the VAE algorithm two networks are jointly learned: an encoder or inference network, as well as a decoder or generative network. In this week you will learn how to implement the VAE using the TensorFlow Probability library. You will then use the trained networks to encode data examples into a compressed latent space, as well as generate new samples from the prior distribution and the decoder. In the programming assignment for this week, you will develop the variational autoencoder for an image dataset of celebrity faces.

---

## Learning Objectives

Understand the definition and derivation of the evidence lower bound (ELBO)
Define and optimize the VAE objective function for a deep learning model with stochastic latent variables
Include KL divergence loss terms in probabilistic layers
Understand the basic principles underlying variational inference in Bayesian statistics.

[Coursera](https://www.coursera.org/learn/probabilistic-deep-learning-with-tensorflow2/home/week/4)
